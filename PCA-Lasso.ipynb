{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import bokeh\n",
    "from bokeh.plotting import figure, output_file, show, ColumnDataSource\n",
    "# import bokeh.charts.utils\n",
    "import bokeh.io\n",
    "import bokeh.models\n",
    "from bokeh.models import HoverTool\n",
    "import bokeh.palettes\n",
    "import bokeh.plotting\n",
    "import random\n",
    "from random import sample\n",
    "from sklearn import svm, neighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "import multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing, normalization done in excel (Xnew = (X-mean)/std))\n",
    "# If we want to normalize in Python we can use preprocessing.scale()\n",
    "Data = pd.read_csv('songs4.csv')\n",
    "Data = Data.iloc[:, 0:18]\n",
    "#Data = Data.drop(Data[(Data.time_signature > 5)].index)\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of rows\n",
    "Data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Divide into testing and training\n",
    "x = Data.drop('valence', 1)\n",
    "y = Data.valence\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.20)\n",
    "train = xtrain.assign(valence=ytrain)\n",
    "train = train [0: 5000]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "M = train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "plt.imshow(M)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD using numpy function\n",
    "U, E, VT = np.linalg.svd(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(E)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.dot(U[:,:2],np.diag(E[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(P[:,0], P[:,1],'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = train.T\n",
    "N.columns = N.iloc[0]\n",
    "N = N.drop('ID')\n",
    "N = N.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 10-15 minutes with all of the data\n",
    "N = N.corr()\n",
    "N.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifies how different songs correlate to each other, there is a fair amount of uniqueness among songs\n",
    "plt.imshow(N)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, E, VT = np.linalg.svd(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most of the variance can be explained using the first 8 or so components\n",
    "plt.plot(E[:20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.dot(U[:,:2],np.diag(E[:2]))\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first two principal components to get an idea of the shape of the data\n",
    "_tools_to_show = 'box_zoom,pan,save,hover,reset,tap,wheel_zoom'        \n",
    "p = figure(plot_width=400, plot_height=400, title=None, tools=_tools_to_show)\n",
    "\n",
    "# add a circle renderer with a size, color, and alpha\n",
    "p.circle(P[:,0], P[:,1], size=4, color=\"navy\", alpha=0.2)\n",
    "\n",
    "# show the results\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM on PCA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further divide training and testing based on principal components\n",
    "# Slice U and E based on the ideal number of principal components\n",
    "P = np.dot(U, np.diag(E))\n",
    "P = P[:,:18]\n",
    "PCA_xtrain, PCA_xtest, PCA_ytrain, PCA_ytest = train_test_split(P, train['valence'], test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_clf = svm.SVR(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_clf.fit(PCA_xtrain, PCA_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing error\n",
    "SVM_test_ypreds = SVM_clf.predict(PCA_xtest)\n",
    "SVM_test_MSE = np.mean((SVM_test_ypreds - PCA_ytest)**2)\n",
    "SVM_test_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_clf.score(PCA_xtest, PCA_ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_clf.score(PCA_xtrain, PCA_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training error\n",
    "SVM_train_ypreds = SVM_clf.predict(PCA_xtrain)\n",
    "SVM_test_MSE = np.mean((SVM_train_ypreds - PCA_ytrain)**2)\n",
    "SVM_test_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest - Harry draft 1\n",
    "RF_ests = []\n",
    "RF_results = []\n",
    "n_estimators_range = range(50, 600, 50)\n",
    "\n",
    "for n_estimators in n_estimators_range:\n",
    "    RF_clf = RandomForestRegressor(n_estimators=n_estimators, n_jobs=-1, random_state = 0)\n",
    "    RF_clf.fit(PCA_xtrain, PCA_ytrain)\n",
    "    RF_ests.append(n_estimators)\n",
    "    RF_results.append(RF_clf.score(PCA_xtest, PCA_ytest))\n",
    "\n",
    "tools_to_show = 'box_zoom,pan,save,hover,reset,tap,wheel_zoom'\n",
    "p_est_res = figure(plot_width=400,\n",
    "                   plot_height=400,\n",
    "                   title=\"Number of Trees vs Accuracy\",\n",
    "                   tools=_tools_to_show,\n",
    "                   x_axis_label=\"Number of Trees\",\n",
    "                   y_axis_label=\"Accuracy\")\n",
    "# add a circle renderer with a size, color, and alpha\n",
    "p_est_res.circle(RF_ests, RF_results, size=10, color=\"green\", alpha=0.5)\n",
    "\n",
    "# show the results\n",
    "show(p_est_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest - Harry draft 2\n",
    "RF_feats = []\n",
    "RF_feats_results = []\n",
    "max_features_range = range(12, 19)\n",
    "for max_features in max_features_range:\n",
    "    RF_clf = RandomForestRegressor(n_estimators=400,\n",
    "                                   max_features=max_features,\n",
    "                                   random_state=0,\n",
    "                                   n_jobs=-1)\n",
    "    RF_clf.fit(PCA_xtrain, PCA_ytrain)\n",
    "    RF_feats.append(max_features)\n",
    "    RF_feats_results.append(RF_clf.score(PCA_xtest, PCA_ytest))\n",
    "tools_to_show = 'box_zoom,pan,save,hover,reset,tap,wheel_zoom'\n",
    "p_est_res = figure(plot_width=400,\n",
    "                   plot_height=400,\n",
    "                   title=\"Max Features vs Accuracy\",\n",
    "                   tools=_tools_to_show,\n",
    "                   x_axis_label=\"Max Features\",\n",
    "                   y_axis_label=\"Accuracy\")\n",
    "# add a circle renderer with a size, color, and alpha\n",
    "p_est_res.circle(RF_feats, RF_feats_results, size=10, color=\"green\", alpha=0.5)\n",
    "# show the results\n",
    "show(p_est_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copies of data without ID\n",
    "xtrain_heir, xtest_heir, ytrain_heir, ytest_heir = train_test_split(xtrain, ytrain, test_size=0.20) \n",
    "xtrain_heir = xtrain_heir.iloc[:, 1:]\n",
    "xtest_heir  = xtest_heir.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest-Neighbors (on original data)\n",
    "print(\"(n, weights):\")\n",
    "for n in [1, 5, 10, 25, 50, 100, 250, 500]:\n",
    "    for weights in ['uniform', 'distance']:\n",
    "        KNN_clf = KNeighborsRegressor(n_neighbors=n, weights=weights, n_jobs=-1)\n",
    "        KNN_clf.fit(xtrain_heir, ytrain_heir)\n",
    "\n",
    "        # Training error\n",
    "        KNN_train_ypreds = KNN_clf.predict(xtrain_heir)\n",
    "        KNN_train_MSE = np.mean((KNN_train_ypreds - ytrain_heir) ** 2)\n",
    "\n",
    "        # Testing error\n",
    "        KNN_test_ypreds = KNN_clf.predict(xtest_heir)\n",
    "        KNN_test_MSE = np.mean((KNN_test_ypreds - ytest_heir) ** 2)\n",
    "        \n",
    "        print(\"({}, {}) -> Train({:.3f}) Test({:.3f})\".format(n, weights, KNN_train_MSE, KNN_test_MSE))\n",
    "        print(\"Score: {:.3f}\".format(KNN_clf.score(xtest_heir, KNN_test_ypreds)))\n",
    "    \n",
    "\"\"\"\n",
    "Values reported are MSE. Higher = worse\n",
    "(n, weights):\n",
    "(1, uniform) -> Train(0.000) Test(0.824)\n",
    "(1, distance) -> Train(0.000) Test(0.824)\n",
    "(5, uniform) -> Train(0.424) Test(0.644)\n",
    "(5, distance) -> Train(0.000) Test(0.536)\n",
    "(10, uniform) -> Train(0.505) Test(0.616)\n",
    "(10, distance) -> Train(0.000) Test(0.489)\n",
    "(25, uniform) -> Train(0.568) Test(0.607)\n",
    "(25, distance) -> Train(0.000) Test(0.467)\n",
    "(50, uniform) -> Train(0.598) Test(0.614)\n",
    "(50, distance) -> Train(0.000) Test(0.466)\n",
    "(100, uniform) -> Train(0.623) Test(0.626)\n",
    "(100, distance) -> Train(0.000) Test(0.471)\n",
    "(250, uniform) -> Train(0.654) Test(0.648)\n",
    "(250, distance) -> Train(0.000) Test(0.485)\n",
    "(500, uniform) -> Train(0.681) Test(0.673)\n",
    "(500, distance) -> Train(0.000) Test(0.501)\n",
    "\n",
    "For whatever reason score always comes out to exactly 1.000\n",
    "From the above, we can't really say anything specific except that distance as a metric seems far more useful than \n",
    "uniform.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso (on it's own)\n",
    "# Train\n",
    "alpha = 0.01\n",
    "lasso_model = linear_model.Lasso(alpha=alpha)\n",
    "lasso_model.fit(xtrain_heir, ytrain_heir)\n",
    "\n",
    "# Training error\n",
    "lasso_train_ypreds = lasso_model.predict(xtrain_heir)\n",
    "lasso_train_MSE = np.mean((lasso_train_ypreds - ytrain_heir) ** 2)\n",
    "\n",
    "# Testing error\n",
    "lasso_test_ypreds = lasso_model.predict(xtest_heir)\n",
    "lasso_test_MSE = np.mean((lasso_test_ypreds - ytest_heir)**2)\n",
    "\n",
    "# Also do linreg for comparison\n",
    "linreg_model = linear_model.LinearRegression()\n",
    "linreg_model.fit(xtrain_heir, ytrain_heir)\n",
    "\n",
    "# Linreg train:\n",
    "linreg_train_ypreds = linreg_model.predict(xtrain_heir)\n",
    "linreg_train_MSE = np.mean((linreg_train_ypreds - ytrain_heir) ** 2)\n",
    "\n",
    "# Linreg test\n",
    "linreg_test_ypreds = linreg_model.predict(xtest_heir)\n",
    "linreg_test_MSE = np.mean((linreg_test_ypreds - ytest_heir) ** 2)\n",
    "\n",
    "\n",
    "# Output\n",
    "print(\"alpha: {}\".format(alpha))\n",
    "print(\"training error (MSE): {}\".format(lasso_train_MSE))\n",
    "print(\"testing  error (MSE): {}\".format(lasso_test_MSE))\n",
    "print(\"training error linreg: \", linreg_train_MSE)\n",
    "print(\"testing error linreg: \", linreg_test_MSE)\n",
    "\n",
    "# Split into new testing/training dataset\n",
    "scaler = lambda row: np.multiply(lasso_model.coef_, row) + lasso_model.intercept_\n",
    "#scaler = lambda row: row\n",
    "lasso_x = np.apply_along_axis(scaler, 1, xtrain_heir)\n",
    "lasso_xtrain, lasso_xtest, lasso_ytrain, lasso_ytest = train_test_split(lasso_x, ytrain_heir, test_size = 0.2, random_state = 0)\n",
    "\n",
    "\n",
    "\n",
    "# Findings (linreg on lasso):\n",
    "# Values reported are MSE. Higher = worse\n",
    "# Alpha=1.00: Train(1.002) Test(0.992) lmao\n",
    "# Alpha=0.10: Train(0.725) Test(0.711)\n",
    "# Alpha=0.01: Train(0.660) Test(0.650)\n",
    "# Basic linreg: Train(0.657) Test(0.649)\n",
    "# Conclusions - useless on its own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest on LASSO. Shouldn't really do anything different from PCA (probably)\n",
    "RF_lasso_clf = RandomForestRegressor()\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "RF_lasso_parameters_rand = {\n",
    "    \"n_estimators\": sp_randint(10, 60),\n",
    "    \"bootstrap\": [True, False],\n",
    "}\n",
    "\n",
    "# run randomized search\n",
    "# Accuracy should be comparable to grid search, but runs much much faster\n",
    "n_iter_search = 20\n",
    "RF_lasso_random_search = RandomizedSearchCV(RF_lasso_clf, param_distributions=RF_lasso_parameters_rand,\n",
    "                                   n_iter=n_iter_search,\n",
    "                                   n_jobs=-1)\n",
    "\n",
    "RF_lasso_random_search.fit(lasso_xtrain, lasso_ytrain)\n",
    "\n",
    "RF_lasso_predicted = RF_lasso_random_search.predict(lasso_xtest)\n",
    "\n",
    "print(\"LASSO with random forest\")\n",
    "RF_lasso_random_search.score(lasso_xtest, lasso_ytest)\n",
    "\n",
    "# FINDINGS (RF on lasso):\n",
    "# Values reported are score. Higher = better\n",
    "# Alpha = 1.00 -> -0.000195\n",
    "# Alpha = 0.10 -> 0.5323 \n",
    "# Alpha = 0.01 -> 0.5261\n",
    "# No Lasso -> 0.5326\n",
    "# Conclusion - way worse than PCA on its own. Shouldn't use it solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest-Neighbors on LASSO\n",
    "print(\"(n, weights):\")\n",
    "weights = 'distance'\n",
    "for n in [1, 2, 3, 5, 10, 25, 50, 100, 250]:\n",
    "    KNN_lasso_clf = KNeighborsRegressor(n_neighbors=n, weights=weights, n_jobs=-1)\n",
    "    KNN_lasso_clf.fit(lasso_xtrain, lasso_ytrain)\n",
    "\n",
    "    # Training error\n",
    "    KNN_lasso_train_ypreds = KNN_lasso_clf.predict(lasso_xtrain)\n",
    "    KNN_lasso_train_MSE = np.mean((KNN_lasso_train_ypreds - lasso_ytrain) ** 2)\n",
    "\n",
    "    # Testing error\n",
    "    KNN_lasso_test_ypreds = KNN_lasso_clf.predict(lasso_xtest)\n",
    "    KNN_lasso_test_MSE = np.mean((KNN_lasso_test_ypreds - lasso_ytest) ** 2)\n",
    "\n",
    "    print(\"({}, {}) -> Train({:.3f}) Test({:.3f})\".format(n, weights, KNN_lasso_train_MSE, KNN_lasso_test_MSE))\n",
    "    \n",
    "\"\"\"\n",
    "Findings (KNN on lasso):\n",
    "Values reported are MSE - higher = worse\n",
    "Alpha = 1.00:\n",
    "Failed (Unbelievably high error, >1.5 and took 3 minutes to run n=1)\n",
    "\n",
    "Alpha = 0.10:\n",
    "(n, weights):\n",
    "(1, distance) -> Train(0.000) Test(1.026)\n",
    "(2, distance) -> Train(0.000) Test(0.795)\n",
    "(3, distance) -> Train(0.000) Test(0.717)\n",
    "(5, distance) -> Train(0.000) Test(0.648)\n",
    "(10, distance) -> Train(0.000) Test(0.594)\n",
    "(25, distance) -> Train(0.000) Test(0.558)\n",
    "(50, distance) -> Train(0.000) Test(0.548)\n",
    "(100, distance) -> Train(0.000) Test(0.547)\n",
    "(250, distance) -> Train(0.000) Test(0.550)\n",
    "\n",
    "\n",
    "Alpha = 0.01:\n",
    "(n, weights):\n",
    "(1, distance) -> Train(0.000) Test(0.901)\n",
    "(2, distance) -> Train(0.000) Test(0.707)\n",
    "(3, distance) -> Train(0.000) Test(0.641)\n",
    "(5, distance) -> Train(0.000) Test(0.577)\n",
    "(10, distance) -> Train(0.000) Test(0.525)\n",
    "(25, distance) -> Train(0.000) Test(0.504)\n",
    "(50, distance) -> Train(0.000) Test(0.502)\n",
    "(100, distance) -> Train(0.000) Test(0.506)\n",
    "(250, distance) -> Train(0.000) Test(0.514)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM on LASSO:\n",
    "print(\"alpha: {}\".format(alpha))\n",
    "SVM_lasso_clf = svm.SVR(kernel='linear')\n",
    "SVM_lasso_clf.fit(lasso_xtrain, lasso_ytrain)\n",
    "\n",
    "# Training error\n",
    "SVM_lasso_train_ypreds = SVM_lasso_clf.predict(lasso_xtrain)\n",
    "SVM_lasso_train_MSE = np.mean((SVM_lasso_train_ypreds - lasso_ytrain) ** 2)\n",
    "\n",
    "# Testing error\n",
    "SVM_lasso_test_ypreds = SVM_lasso_clf.predict(lasso_xtest)\n",
    "SVM_lasso_test_MSE = np.mean((SVM_lasso_test_ypreds - lasso_ytest) ** 2)\n",
    "print(\"Error MSE: Train({:.3f}) Test({:.3f})\".format(SVM_lasso_train_MSE, SVM_lasso_test_MSE))\n",
    "\n",
    "\"\"\"\n",
    "Results:\n",
    "(Note: results given in MSE. Higher = worse)\n",
    "Alpha = 1.0:\n",
    "Error MSE: Train(0.999) Test(1.016) \n",
    "\n",
    "Alpha = 0.1:\n",
    "Error MSE: Train(0.704) Test(0.724)\n",
    "\n",
    "Alpha = 0.01:\n",
    "Error MSE: Train(0.660) Test(0.672)\n",
    "\n",
    "Conclusion: It's garbo\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso on PCA\n",
    "# Train\n",
    "alpha = 0.01\n",
    "PCA_lasso_model = linear_model.Lasso(alpha=alpha)\n",
    "PCA_lasso_model.fit(PCA_xtrain, PCA_ytrain)\n",
    "\n",
    "# Training error\n",
    "PCA_lasso_train_ypreds = PCA_lasso_model.predict(PCA_xtrain)\n",
    "PCA_lasso_train_MSE = np.mean((PCA_lasso_train_ypreds - PCA_ytrain) ** 2)\n",
    "\n",
    "# Testing error\n",
    "PCA_lasso_test_ypreds = PCA_lasso_model.predict(PCA_xtest)\n",
    "PCA_lasso_test_MSE = np.mean((PCA_lasso_test_ypreds - PCA_ytest) ** 2)\n",
    "\n",
    "# Also do linreg for comparison\n",
    "PCA_linreg_model = linear_model.LinearRegression()\n",
    "PCA_linreg_model.fit(PCA_xtrain, PCA_ytrain)\n",
    "\n",
    "# Linreg train:\n",
    "PCA_linreg_train_ypreds = PCA_linreg_model.predict(PCA_xtrain)\n",
    "PCA_linreg_train_MSE = np.mean((PCA_linreg_train_ypreds - PCA_ytrain) ** 2)\n",
    "\n",
    "# Linreg test\n",
    "PCA_linreg_test_ypreds = PCA_linreg_model.predict(PCA_xtest)\n",
    "PCA_linreg_test_MSE = np.mean((PCA_linreg_test_ypreds - PCA_ytest) ** 2)\n",
    "\n",
    "\n",
    "# Output\n",
    "print(\"alpha: {}\".format(alpha))\n",
    "print(\"training error (MSE): {}\".format(PCA_lasso_train_MSE))\n",
    "print(\"testing  error (MSE): {}\".format(PCA_lasso_test_MSE))\n",
    "print(\"training error linreg: \", PCA_linreg_train_MSE)\n",
    "print(\"testing error linreg: \", PCA_linreg_test_MSE)\n",
    "\n",
    "# Split into new testing/training dataset\n",
    "scaler = lambda row: np.multiply(PCA_lasso_model.coef_, row) + PCA_lasso_model.intercept_\n",
    "PCA_lasso_x = np.apply_along_axis(scaler, 1, PCA_xtrain)\n",
    "PCA_lasso_xtrain, PCA_lasso_xtest, PCA_lasso_ytrain, PCA_lasso_ytest = train_test_split(PCA_lasso_x, PCA_ytrain, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# FINDINGS (linreg on PCA->Lasso)\n",
    "# Values reported are MSE: Higher = worse\n",
    "# Alpha = 1.00-> Train(0.2810) Test(0.2913)\n",
    "# Alpha = 0.10-> Train(0.0881) Test(0.0971)\n",
    "# Alpha = 0.01-> Train(0.0670) Test(0.0737)\n",
    "# No Lasso (linreg normally): Train(0.064) Test(0.071)\n",
    "# Conclusion: Lasso on PCA doesn't help for just linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM on PCA->LASSO:\n",
    "print(\"alpha: {}\".format(alpha))\n",
    "SVM_PCA_lasso_clf = svm.SVR(kernel='linear')\n",
    "SVM_PCA_lasso_clf.fit(PCA_lasso_xtrain, PCA_lasso_ytrain)\n",
    "\n",
    "# Training error\n",
    "SVM_PCA_lasso_train_ypreds = SVM_PCA_lasso_clf.predict(PCA_lasso_xtrain)\n",
    "SVM_PCA_lasso_train_MSE = np.mean((SVM_PCA_lasso_train_ypreds - PCA_lasso_ytrain) ** 2)\n",
    "\n",
    "# Testing error\n",
    "SVM_PCA_lasso_test_ypreds = SVM_PCA_lasso_clf.predict(PCA_lasso_xtest)\n",
    "SVM_PCA_lasso_test_MSE = np.mean((SVM_PCA_lasso_test_ypreds - PCA_lasso_ytest) ** 2)\n",
    "print(\"Error MSE: Train({:.3f}) Test({:.3f})\".format(SVM_PCA_lasso_train_MSE, SVM_PCA_lasso_test_MSE))\n",
    "\n",
    "\"\"\"\n",
    "Results:\n",
    "Alpha = 1.00\n",
    "Error MSE: Train(0.177) Test(0.177)\n",
    "\n",
    "Alpha = 0.10\n",
    "Train(0.086) Test(0.075)\n",
    "\n",
    "Alpha = 0.01:\n",
    "Train(0.069) Test(0.064) <--- WOW -- equiv to a score of 0.936\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced SVM on PCA->LASSO utilizing  different values of C\n",
    "C_range = 10. ** np.arange(4, 7)\n",
    "C_MSE = []\n",
    "\n",
    "# HERE: PCALSVMC is PCA->Lasso->SVM with C param\n",
    "def computePCALSVMC_MSE(C):\n",
    "    PCALSVMC_clf = svm.SVR(kernel='rbf', C = C)\n",
    "    PCALSVMC_clf.fit(PCA_lasso_xtrain, PCA_lasso_ytrain)\n",
    "    PCALSVMC_test_ypreds = PCALSVMC_clf.predict(PCA_lasso_xtest)\n",
    "    PCALSVMC_test_MSE = np.mean((PCALSVMC_test_ypreds - PCA_lasso_ytest)**2)\n",
    "    return PCALSVMC_test_MSE\n",
    "\n",
    "C_MSE = pool.map(computePCALSVMC_MSE, C_range)\n",
    "    \n",
    "print(\"alpha: {}\".format(alpha))\n",
    "for c, mse in zip(C_range, C_MSE):\n",
    "    print(\"C({}) MSE({})\".format(c, mse))\n",
    "    \n",
    "\"\"\"\n",
    "alpha: 0.01\n",
    "C(0.001) MSE(0.9956695791988903)\n",
    "C(0.01) MSE(0.9923254768785487)\n",
    "C(0.1) MSE(0.9594169761856932)\n",
    "C(1.0) MSE(0.6872493268512234)\n",
    "C(10.0) MSE(0.1496952613657234)\n",
    "C(100.0) MSE(0.08604381918340415)\n",
    "C(1000.0) MSE(0.0787053108083247)\n",
    "C(10000.0) MSE(0.07034445994490687)\n",
    "C(50000) MSE(0.059558527959229696)\n",
    "C(100000.0) MSE(0.054695510721515204)\n",
    "C(150000) MSE(0.05171920548369242)\n",
    "C(1000000.0) MSE(0.0736315107354647)\n",
    "C(10000000.0) MSE(4.197551598806395)\n",
    "C(100000000.0) MSE(356.09536694427385)\n",
    "\n",
    "POST DROP TO \"REAL\" COMPONENTS:\n",
    "C(0.01) MSE(0.9923254768785487)\n",
    "C(0.1) MSE(0.9594169761856932)\n",
    "C(1.0) MSE(0.6872493268512234)\n",
    "C(10.0) MSE(0.1496952613657234)\n",
    "C(100.0) MSE(0.08604381918340415)\n",
    "C(1000.0) MSE(0.0787053108083247)\n",
    "C(10000.0) MSE(0.07034445994490687)\n",
    "C(100000.0) MSE(0.054695510721515204)\n",
    "C(1000000.0) MSE(0.0736315107354647)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot values of C vs MSE\n",
    "_tools_to_show = 'box_zoom,pan,save,hover,reset,tap,wheel_zoom'        \n",
    "p_C_MSE = figure(plot_width=400, plot_height=400, title=None, tools=_tools_to_show)\n",
    "\n",
    "# add a circle renderer with a size, color, and alpha\n",
    "p_C_MSE.circle (C_range, C_MSE, size=10, color=\"green\", alpha=0.5)\n",
    "\n",
    "# show the results\n",
    "show(p_C_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using our optimal value of C, we cross validate to find the optimal value of gamma\n",
    "from itertools import chain\n",
    "gamma_range = chain(10. ** np.arange(-5, 1), [0.2, 0.3, 0.4])\n",
    "def computePCALSVMC_MSE_GAMMA(g): \n",
    "    PCALSVMC_clf = svm.SVR(kernel='rbf', C = 150000, gamma = g)\n",
    "    PCALSVMC_clf.fit(PCA_lasso_xtrain, PCA_lasso_ytrain)\n",
    "    PCALSVMC_test_ypreds = PCALSVMC_clf.predict(PCA_lasso_xtest)\n",
    "    PCALSVMC_test_MSE = np.mean((PCALSVMC_test_ypreds - PCA_lasso_ytest)**2)\n",
    "    gamma_MSE.append(PCALSVMC_test_MSE)\n",
    "    \n",
    "    \n",
    "gamma_MSE = pool.map(computePCALSVMC_MSE_GAMMA, gamma_range)\n",
    "    \n",
    "print(\"alpha: {}\".format(alpha))\n",
    "print(\"C = 150000\")\n",
    "for c, mse in zip(gamma_range, gamma_MSE):\n",
    "    print(\"gamma({}) MSE({})\".format(c, mse)) \n",
    "   \n",
    "\n",
    "\n",
    "'''\n",
    "C = 15000\n",
    "gamma(1e-05) MSE(0.08045146016190116)\n",
    "gamma(0.0001) MSE(0.06162189690329871)\n",
    "gamma(0.001) MSE(0.028257963289700597)\n",
    "gamma(0.01) MSE(0.009621058122301473)\n",
    "gamma(0.1) MSE(0.008151309634909475)\n",
    "gamma(0.2) MSE(0.009688701255743915)\n",
    "gamma(0.3) MSE(0.009684018266092493)\n",
    "gamma(0.4) MSE(0.009733114479588486)\n",
    "gamma(1.0) MSE(0.010803416697807116)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, mse in zip(gamma_range, gamma_MSE):\n",
    "    print(\"gamma({}) MSE({})\".format(c, mse)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest on PCA->LASSO:\n",
    "RF_PCA_lasso_clf = RandomForestRegressor()\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "RF_PCA_lasso_parameters_rand = {\n",
    "    \"n_estimators\": sp_randint(10, 60),\n",
    "    \"bootstrap\": [True, False]\n",
    "}\n",
    "\n",
    "# run randomized search\n",
    "# Accuracy should be comparable to grid search, but runs much much faster\n",
    "n_iter_search = 20\n",
    "RF_PCA_lasso_random_search = RandomizedSearchCV(RF_PCA_lasso_clf, param_distributions=RF_PCA_lasso_parameters_rand,\n",
    "                                    n_iter=n_iter_search,\n",
    "                                    n_jobs=-1,\n",
    "                                    random_state=0)\n",
    "\n",
    "RF_PCA_lasso_random_search.fit(PCA_lasso_xtrain, PCA_lasso_ytrain)\n",
    "\n",
    "RF_PCA_lasso_predicted = RF_PCA_lasso_random_search.predict(PCA_lasso_xtest)\n",
    "\n",
    "print(\"PCA->LASSO with random forest\")\n",
    "print(\"alpha = {}\".format(alpha))\n",
    "RF_PCA_lasso_random_search.score(PCA_lasso_xtest, PCA_lasso_ytest)\n",
    "\n",
    "# FINDINGS (RF on PCA->lasso):\n",
    "# Values reported are score. Higher = better\n",
    "# Alpha = 1.00 -> 0.852\n",
    "# Alpha = 0.10 -> 0.911\n",
    "# Alpha = 0.01 -> 0.910\n",
    "# No lasso (taken from above) -> 0.914\n",
    "# Conclusion: It isn't the worst thing in the world, but is ultimately probably worse than RF on PCA without lasso\n",
    "# Note that unless seeded, results vary fairly significantly from run to run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest-Neighbors on PCA->LASSO\n",
    "print(\"alpha = {}\".format(alpha))\n",
    "print(\"(n, weights):\")\n",
    "weights = 'distance'\n",
    "for n in [1, 2, 3, 5, 10, 25, 50, 100, 250]:\n",
    "    KNN_PCA_lasso_clf = KNeighborsRegressor(n_neighbors=n, weights=weights, n_jobs=-1)\n",
    "    KNN_PCA_lasso_clf.fit(PCA_lasso_xtrain, PCA_lasso_ytrain)\n",
    "\n",
    "    # Training error\n",
    "    KNN_PCA_lasso_train_ypreds = KNN_PCA_lasso_clf.predict(PCA_lasso_xtrain)\n",
    "    KNN_PCA_lasso_train_MSE = np.mean((KNN_PCA_lasso_train_ypreds - PCA_lasso_ytrain) ** 2)\n",
    "\n",
    "    # Testing error\n",
    "    KNN_PCA_lasso_test_ypreds = KNN_PCA_lasso_clf.predict(PCA_lasso_xtest)\n",
    "    KNN_PCA_lasso_test_MSE = np.mean((KNN_PCA_lasso_test_ypreds - PCA_lasso_ytest) ** 2)\n",
    "\n",
    "    print(\"({}, {}) -> Train({:.3f}) Test({:.3f})\".format(n, weights, KNN_PCA_lasso_train_MSE, KNN_PCA_lasso_test_MSE))\n",
    "    \n",
    "\"\"\"\n",
    "Findings (KNN on PCA->lasso):\n",
    "Values reported are MSE - higher = worse\n",
    "Alpha = 1.00:\n",
    "(n, weights):\n",
    "(1, distance) -> Train(0.000) Test(0.261)\n",
    "(2, distance) -> Train(0.000) Test(0.194)\n",
    "(3, distance) -> Train(0.000) Test(0.171)\n",
    "(5, distance) -> Train(0.000) Test(0.153)\n",
    "(10, distance) -> Train(0.000) Test(0.143)\n",
    "(25, distance) -> Train(0.000) Test(0.145)\n",
    "(50, distance) -> Train(0.000) Test(0.152)\n",
    "(100, distance) -> Train(0.000) Test(0.170)\n",
    "(250, distance) -> Train(0.000) Test(0.213)\n",
    "\n",
    "Alpha = 0.10:\n",
    "(n, weights):\n",
    "(1, distance) -> Train(0.000) Test(0.153)\n",
    "(2, distance) -> Train(0.000) Test(0.105)\n",
    "(3, distance) -> Train(0.000) Test(0.088)\n",
    "(5, distance) -> Train(0.000) Test(0.077)\n",
    "(10, distance) -> Train(0.000) Test(0.078)\n",
    "(25, distance) -> Train(0.000) Test(0.084)\n",
    "(50, distance) -> Train(0.000) Test(0.099)\n",
    "(100, distance) -> Train(0.000) Test(0.121)\n",
    "(250, distance) -> Train(0.000) Test(0.165)\n",
    "\n",
    "\n",
    "Alpha = 0.01:\n",
    "(n, weights):\n",
    "(1, distance) -> Train(0.000) Test(0.141)\n",
    "(2, distance) -> Train(0.000) Test(0.096)\n",
    "(3, distance) -> Train(0.000) Test(0.081)\n",
    "(5, distance) -> Train(0.000) Test(0.073)\n",
    "(10, distance) -> Train(0.000) Test(0.075)\n",
    "(25, distance) -> Train(0.000) Test(0.083)\n",
    "(50, distance) -> Train(0.000) Test(0.098)\n",
    "(100, distance) -> Train(0.000) Test(0.120)\n",
    "(250, distance) -> Train(0.000) Test(0.162)\n",
    "\n",
    "alpha = 0.001\n",
    "(n, weights):\n",
    "(1, distance) -> Train(0.000) Test(0.140)\n",
    "(2, distance) -> Train(0.000) Test(0.097)\n",
    "(3, distance) -> Train(0.000) Test(0.081)\n",
    "(5, distance) -> Train(0.000) Test(0.072)\n",
    "(10, distance) -> Train(0.000) Test(0.073)\n",
    "(25, distance) -> Train(0.000) Test(0.083)\n",
    "(50, distance) -> Train(0.000) Test(0.098)\n",
    "(100, distance) -> Train(0.000) Test(0.120)\n",
    "(250, distance) -> Train(0.000) Test(0.162)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest-Neighbors on PCA (probably should've done this one first)\n",
    "print(\"alpha = {}\".format(alpha))\n",
    "print(\"(n, weights):\")\n",
    "weights = 'distance'\n",
    "for n in [1, 2, 3, 5, 10, 25, 50, 100, 250]:\n",
    "    KNN_PCA_clf = KNeighborsRegressor(n_neighbors=n, weights=weights, n_jobs=-1)\n",
    "    KNN_PCA_clf.fit(PCA_xtrain, PCA_ytrain)\n",
    "\n",
    "    # Training error\n",
    "    KNN_PCA_train_ypreds = KNN_PCA_clf.predict(PCA_xtrain)\n",
    "    KNN_PCA_train_MSE = np.mean((KNN_PCA_train_ypreds - PCA_ytrain) ** 2)\n",
    "\n",
    "    # Testing error\n",
    "    KNN_PCA_test_ypreds = KNN_PCA_clf.predict(PCA_xtest)\n",
    "    KNN_PCA_test_MSE = np.mean((KNN_PCA_test_ypreds - PCA_ytest) ** 2)\n",
    "\n",
    "    print(\"({}, {}) -> Train({:.3f}) Test({:.3f})\".format(n, weights, KNN_PCA_train_MSE, KNN_PCA_test_MSE))\n",
    "    \n",
    "\"\"\"\n",
    "Findings (KNN on PCA):\n",
    "Values reported are MSE - higher = worse\n",
    "(n, weights):\n",
    "(1, distance) -> Train(0.000) Test(0.205)\n",
    "(2, distance) -> Train(0.000) Test(0.141)\n",
    "(3, distance) -> Train(0.000) Test(0.119)\n",
    "(5, distance) -> Train(0.000) Test(0.111)\n",
    "(10, distance) -> Train(0.000) Test(0.110)\n",
    "(25, distance) -> Train(0.000) Test(0.133)\n",
    "(50, distance) -> Train(0.000) Test(0.163)\n",
    "(100, distance) -> Train(0.000) Test(0.199)\n",
    "(250, distance) -> Train(0.000) Test(0.266)\n",
    "\n",
    "Note: Seems to run noticeably slower than lasso \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
