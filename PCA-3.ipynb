{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import bokeh\n",
    "from bokeh.plotting import figure, output_file, show, ColumnDataSource\n",
    "# import bokeh.charts.utils\n",
    "import bokeh.io\n",
    "import bokeh.models\n",
    "from bokeh.models import HoverTool\n",
    "import bokeh.palettes\n",
    "import bokeh.plotting\n",
    "import random\n",
    "from random import sample\n",
    "from sklearn import svm, neighbors\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing, normalization done in excel (Xnew = (X-mean)/std))\n",
    "# If we want to normalize in Python we can use preprocessing.scale()\n",
    "Data = pd.read_csv('songs4.csv')\n",
    "Data = Data.iloc[:, 0:18]\n",
    "#Data = Data.drop(Data[(Data.time_signature > 5)].index)\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of rows\n",
    "Data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Divide into testing and training\n",
    "x = Data.drop('valence', 1)\n",
    "y = Data.valence\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.20)\n",
    "train = xtrain\n",
    "train['valence'] = ytrain\n",
    "train = train [0: 5000]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "M = train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "plt.imshow(M)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD using numpy function\n",
    "U, E, VT = np.linalg.svd(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(E)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.dot(U[:,:2],np.diag(E[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(P[:,0], P[:,1],'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = train.T\n",
    "N.columns = N.iloc[0]\n",
    "N = N.drop('ID')\n",
    "N = N.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 10-15 minutes with all of the data\n",
    "N = N.corr()\n",
    "N.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifies how different songs correlate to each other, there is a fair amount of uniqueness among songs\n",
    "plt.imshow(N)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, E, VT = np.linalg.svd(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most of the variance can be explained using the first 8 or so components\n",
    "plt.plot(E[:10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.dot(U[:,:2],np.diag(E[:2]))\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first two principal components to get an idea of the shape of the data\n",
    "_tools_to_show = 'box_zoom,pan,save,hover,reset,tap,wheel_zoom'        \n",
    "p = figure(plot_width=400, plot_height=400, title=None, tools=_tools_to_show)\n",
    "\n",
    "# add a circle renderer with a size, color, and alpha\n",
    "p.circle(P[:,0], P[:,1], size=4, color=\"navy\", alpha=0.2)\n",
    "\n",
    "# show the results\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM on PCA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further divide training and testing based on principal components\n",
    "# Slice U and E based on the ideal number of principal components\n",
    "P = np.dot(U,np.diag(E))\n",
    "P = P[:,:18]\n",
    "PCA_xtrain, PCA_xtest, PCA_ytrain, PCA_ytest = train_test_split(P, train['valence'], test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_clf = svm.SVR(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_clf.fit(PCA_xtrain, PCA_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing error\n",
    "SVM_test_ypreds = SVM_clf.predict(PCA_xtest)\n",
    "MSE = np.mean((SVM_test_ypreds - PCA_ytest)**2)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_clf.score(PCA_xtest, PCA_ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_clf.score(PCA_xtrain, PCA_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training error\n",
    "SVM_train_ypreds = SVM_clf.predict(PCA_xtrain)\n",
    "SVM_test_MSE = np.mean((SVM_train_ypreds - PCA_ytrain)**2)\n",
    "SVM_test_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validate for values of C and gamma, start by defining the ranges for each\n",
    "C_range = [2.0, 3.0]\n",
    "\n",
    "# Cross validate for optimal value of C\n",
    "def f(i):\n",
    "    SVM_clf_C = svm.SVR(kernel='linear', C = i)\n",
    "    SVM_clf_C.fit(PCA_xtrain, PCA_ytrain)\n",
    "    SVM_test_ypreds_C = SVM_clf_C.predict(PCA_xtest)\n",
    "    SVM_test_MSE_C = np.mean((SVM_test_ypreds_C - PCA_ytest)**2)\n",
    "    print(i)\n",
    "    return SVM_test_MSE_C\n",
    "    \n",
    "pool = mp.Pool(processes=8)\n",
    "C_MSE = pool.map(f, C_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot values of C vs MSE\n",
    "_tools_to_show = 'box_zoom,pan,save,hover,reset,tap,wheel_zoom'        \n",
    "p_C_MSE = figure(plot_width=400, plot_height=400, title=None, tools=_tools_to_show)\n",
    "\n",
    "# add a circle renderer with a size, color, and alpha\n",
    "p_C_MSE.circle (C_range, C_MSE, size=10, color=\"green\", alpha=0.5)\n",
    "\n",
    "# show the results\n",
    "print(C_MSE)\n",
    "show(p_C_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using our optimal value of C, we cross validate to find the optimal value of gamma\n",
    "\n",
    "def f2(i)\n",
    "    SVM_clf_gamma = svm.SVR(kernel='rbf', C = 100, gamma = i)\n",
    "    SVM_clf_gamma.fit(PCA_xtrain, PCA_ytrain)\n",
    "    SVM_test_ypreds_gamma = SVM_clf_gamma.predict(PCA_xtest)\n",
    "    SVM_test_MSE_gamma = np.mean((SVM_train_ypreds - PCA_ytest)**2)\n",
    "    gamma_MSE.append(SVM_test_MSE_gamma)\n",
    "    \n",
    "gamma_MSE = pool.map(f2, gamma_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot various values of gamma vs MSE\n",
    "_tools_to_show = 'box_zoom,pan,save,hover,resize,reset,tap,wheel_zoom'        \n",
    "p_gamma_MSE = figure(plot_width=400, plot_height=400, title=None, tools=_tools_to_show)\n",
    "\n",
    "# add a circle renderer with a size, color, and alpha\n",
    "p_gamma_MSE.circle (gamma_range, gamma_MSE, size=10, color=\"orange\", alpha=0.5)\n",
    "\n",
    "# show the results\n",
    "show(p_gamma_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "RF_clf = RandomForestRegressor()\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "parameters_rand = {\n",
    "    \"n_estimators\": sp_randint(10, 60),\n",
    "    \"bootstrap\": [True, False],\n",
    "}\n",
    "\n",
    "# run randomized search\n",
    "# Accuracy should be comparable to grid search, but runs much much faster\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(RF_clf, param_distributions=parameters_rand,\n",
    "                                   n_iter=n_iter_search,\n",
    "                                   n_jobs=-1)\n",
    "\n",
    "random_search.fit(PCA_xtrain, PCA_ytrain)\n",
    "\n",
    "predicted = random_search.predict(PCA_xtest)\n",
    "\n",
    "print(\"PCA with random forest\")\n",
    "random_search.score(PCA_xtest, PCA_ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso (on it's own)\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Train\n",
    "lasso_models = {} # Keyed by alpha\n",
    "xtrain_no_id = xtrain.iloc[:, 1:]\n",
    "xtest_no_id  = xtest.iloc[:, 1:]\n",
    "\n",
    "for alpha in [0.01, 0.05, 0.1, 0.2, 0.5, 0.7, 1.0]:\n",
    "    lasso_model = linear_model.Lasso(alpha=alpha)\n",
    "    lasso_model.fit(xtrain_no_id, ytrain)\n",
    "    \n",
    "    # Training error\n",
    "    lasso_train_ypreds = lasso_model.predict(xtrain_no_id)\n",
    "    lasso_train_MSE = np.mean((lasso_train_ypreds - ytrain) ** 2)\n",
    "    \n",
    "    # Testing error\n",
    "    lasso_test_ypreds = lasso_model.predict(xtest_no_id)\n",
    "    lasso_test_MSE = np.mean((lasso_test_ypreds - ytest)**2)\n",
    "    \n",
    "    # Output\n",
    "    print(\"alpha: {}\".format(alpha))\n",
    "    print(\"training error: {}\".format(lasso_train_MSE))\n",
    "    print(\"testing  error: {}\".format(lasso_test_MSE))\n",
    "    \n",
    "    # Save\n",
    "    lasso_models[alpha] = lasso_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jig = neighbors.KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jig.fit(PCA_xtrain, PCA_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_test_ypreds = jig.predict(PCA_xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_test_MSE = np.mean((y_pred2 - y_test)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_test_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jig.score(PCA_xtest, PCA_ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = PCA_xtrain.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation for KNN  \n",
    "kf = KFold(n_samples, n_folds=5, shuffle=False)\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use cross validation to find the optimal number of k\n",
    "k  = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "knn_test_MSE_k = []\n",
    "for i in k: \n",
    "    knn = KNeighborsRegressor(n_neighbors=i)\n",
    "    scores = cross_val_score(knn, PCA_xtrain, PCA_ytrain, cv=5, scoring='neg_mean_squared_error')\n",
    "    MSE_k = abs(sum(scores))/5\n",
    "    knn_test_MSE_k.append(MSE_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph number of k vs mse\n",
    "_tools_to_show = 'box_zoom,pan,save,hover,resize,reset,tap,wheel_zoom'        \n",
    "p_knn_MSE = figure(plot_width=400, plot_height=400, title=None, tools=_tools_to_show)\n",
    "\n",
    "# add a circle renderer with a size, color, and alpha\n",
    "p_knn_MSE.circle (k, knn_test_MSE, size=10, color=\"red\", alpha=0.5)\n",
    "\n",
    "# show the results\n",
    "show(p_knn_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_xtrain.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
