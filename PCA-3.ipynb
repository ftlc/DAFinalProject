{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import bokeh\n",
    "from bokeh.plotting import figure, output_file, show, ColumnDataSource\n",
    "# import bokeh.charts.utils\n",
    "import bokeh.io\n",
    "import bokeh.models\n",
    "from bokeh.models import HoverTool\n",
    "import bokeh.palettes\n",
    "import bokeh.plotting\n",
    "import random\n",
    "from random import sample\n",
    "from sklearn import svm, neighbors\n",
    "\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing, normalization done in excel (Xnew = (X-mean)/std))\n",
    "# If we want to normalize in Python we can use preprocessing.scale()\n",
    "Data = pd.read_csv('songs4.csv')\n",
    "Data = Data.iloc[:, 0:18]\n",
    "#Data = Data.drop(Data[(Data.time_signature > 5)].index)\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of rows\n",
    "Data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Divide into testing and training\n",
    "x = Data.drop('valence', 1)\n",
    "y = Data.valence\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.20)\n",
    "train = xtrain.assign(valence=ytrain)\n",
    "train = train [0: 5000]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "M = train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "plt.imshow(M)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD using numpy function\n",
    "U, E, VT = np.linalg.svd(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(E)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.dot(U[:,:2],np.diag(E[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(P[:,0], P[:,1],'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = train.T\n",
    "N.columns = N.iloc[0]\n",
    "N = N.drop('ID')\n",
    "N = N.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 10-15 minutes with all of the data\n",
    "N = N.corr()\n",
    "N.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifies how different songs correlate to each other, there is a fair amount of uniqueness among songs\n",
    "plt.imshow(N)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, E, VT = np.linalg.svd(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most of the variance can be explained using the first 8 or so components\n",
    "plt.plot(E[:10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.dot(U[:,:2],np.diag(E[:2]))\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first two principal components to get an idea of the shape of the data\n",
    "_tools_to_show = 'box_zoom,pan,save,hover,reset,tap,wheel_zoom'        \n",
    "p = figure(plot_width=400, plot_height=400, title=None, tools=_tools_to_show)\n",
    "\n",
    "# add a circle renderer with a size, color, and alpha\n",
    "p.circle(P[:,0], P[:,1], size=4, color=\"navy\", alpha=0.2)\n",
    "\n",
    "# show the results\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM on PCA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further divide training and testing based on principal components\n",
    "# Slice U and E based on the ideal number of principal components\n",
    "P = np.dot(U, np.diag(E))\n",
    "PCA_xtrain, PCA_xtest, PCA_ytrain, PCA_ytest = train_test_split(P, train['valence'], test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_clf = svm.SVR(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_clf.fit(PCA_xtrain, PCA_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing error\n",
    "SVM_test_ypreds = SVM_clf.predict(PCA_xtest)\n",
    "SVM_test_MSE = np.mean((SVM_test_ypreds - PCA_ytest)**2)\n",
    "SVM_test_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_clf.score(PCA_xtest, PCA_ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_clf.score(PCA_xtrain, PCA_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training error\n",
    "SVM_train_ypreds = SVM_clf.predict(PCA_xtrain)\n",
    "SVM_test_MSE = np.mean((SVM_train_ypreds - PCA_ytrain)**2)\n",
    "SVM_test_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "RF_clf = RandomForestRegressor()\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "parameters_rand = {\n",
    "    \"n_estimators\": sp_randint(10, 60),\n",
    "    \"bootstrap\": [True, False],\n",
    "}\n",
    "\n",
    "# run randomized search\n",
    "# Accuracy should be comparable to grid search, but runs much much faster\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(RF_clf, param_distributions=parameters_rand,\n",
    "                                   n_iter=n_iter_search,\n",
    "                                   n_jobs=-1)\n",
    "\n",
    "random_search.fit(PCA_xtrain, PCA_ytrain)\n",
    "\n",
    "predicted = random_search.predict(PCA_xtest)\n",
    "\n",
    "print(\"PCA with random forest\")\n",
    "random_search.score(PCA_xtest, PCA_ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso (on it's own)\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Train\n",
    "lasso_models = {} # Keyed by alpha\n",
    "xtrain_no_id = xtrain.iloc[:, 1:]\n",
    "xtest_no_id  = xtest.iloc[:, 1:]\n",
    "\n",
    "for alpha in [0.01, 0.05, 0.1, 0.2, 0.5, 0.7, 1.0]:\n",
    "    lasso_model = linear_model.Lasso(alpha=alpha)\n",
    "    lasso_model.fit(xtrain_no_id, ytrain)\n",
    "    \n",
    "    # Training error\n",
    "    lasso_train_ypreds = lasso_model.predict(xtrain_no_id)\n",
    "    lasso_train_MSE = np.mean((lasso_train_ypreds - ytrain) ** 2)\n",
    "    \n",
    "    # Testing error\n",
    "    lasso_test_ypreds = lasso_model.predict(xtest_no_id)\n",
    "    lasso_test_MSE = np.mean((lasso_test_ypreds - ytest)**2)\n",
    "    \n",
    "    # Output\n",
    "    print(\"alpha: {}\".format(alpha))\n",
    "    print(\"training error: {}\".format(lasso_train_MSE))\n",
    "    print(\"testing  error: {}\".format(lasso_test_MSE))\n",
    "    \n",
    "    # Save\n",
    "    lasso_models[alpha] = lasso_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
